import os
import json
import warnings
import numpy as np
import pandas as pd
import pandas_ta as ta
import requests
import time
import joblib # Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Scikit-learn
import tensorflow as tf # Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ LSTM
from flask import Flask, request, jsonify, render_template

# ---------------------------------------------------------
# Û±. Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒØŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ú©Ù…Ú©ÛŒ (GLOBAL)
# ---------------------------------------------------------

warnings.filterwarnings('ignore')

class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer): return int(obj)
        elif isinstance(obj, np.floating): return float(obj)
        elif isinstance(obj, np.ndarray): return obj.tolist()
        return json.JSONEncoder.default(self, obj)

app = Flask(__name__)
app.json_encoder = NumpyEncoder

# ğŸ”‘ API KEYS
API_KEY_TWELVEDATA = os.environ.get("TWELVEDATA_API_KEY") 
API_KEY_ALPHA = os.environ.get("ALPHA_VANTAGE_API_KEY") 

# ğŸ“Š Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØªØ±ÛŒØ¯ÛŒÙ†Ú¯ (Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø´Ù…Ø§ Ù¾Ø± Ø´ÙˆÙ†Ø¯)
RISK_REWARD_ATR = 1.5           
TARGET_PERIODS = 5              
ML_CONFIDENCE_THRESHOLD = 1.0   
SIGNAL_SCORE_THRESHOLD = 5.0    
LSTM_TIME_STEPS = 10 

# ğŸ§  Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ Scaler ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø± Ø¯Ø± Ø²Ù…Ø§Ù† Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ
try:
    lstm_model = tf.keras.models.load_model('models/lstm_model.h5')
    rf_model = joblib.load('models/rf_model.pkl')
    lr_model = joblib.load('models/lr_model.pkl')
    xgb_model = joblib.load('models/xgb_model.pkl')
    scaler = joblib.load('models/scaler.pkl') 
    GLOBAL_MODELS_LOADED = True
    print("âœ… All ML models and scaler loaded successfully at startup.")
except Exception as e:
    GLOBAL_MODELS_LOADED = False
    print(f"âŒ WARNING: Failed to load models. Running in basic mode. Error: {e}")
    # Ø§Ú¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù¾ÛŒØ¯Ø§ Ù†Ø´ÙˆÙ†Ø¯ØŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ú©Ø±Ø´ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ø§Ù…Ø§ ØªØ­Ù„ÛŒÙ„ AI ØºÛŒØ±ÙØ¹Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

# ---------------------------------------------------------
# Û². ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ (Helper Functions)
# ---------------------------------------------------------
# ØªÙˆØ§Ø¨Ø¹ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø´Ù…Ø§ (calculate_indicators_and_targetsØŒ check_targetØŒ get_candlesØŒ check_divergenceØŒ calculate_smart_sl_tp) 
# Ú©Ù‡ Ù…Ù†Ø·Ù‚ Ø¢Ù†â€ŒÙ‡Ø§ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø§Ø³ØªØŒ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.

# ØªÙˆØ¬Ù‡: Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨ÙˆØ¯Ù† Ú©Ø¯ ØªÙˆØ§Ø¨Ø¹ØŒ Ø§Ø² Ø¯Ø±Ø¬ Ù…Ø¬Ø¯Ø¯ Ø¢Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù….
# ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ù…Ù†Ø·Ù‚ Ú©Ø§Ù…Ù„ ØªÙˆØ§Ø¨Ø¹ Ø²ÛŒØ± Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ main.py Ø­ÙØ¸ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯:
# - get_candles(symbol, interval, size=2000)
# - check_target(row, df_full, periods, rr_atr)
# - check_divergence(df)
# - get_market_sentiment(symbol)
# - calculate_smart_sl_tp(entry, signal, atr, support, resistance)
# - calculate_indicators_and_targets(df)

# *** ØªØºÛŒÛŒØ±: ØªØ§Ø¨Ø¹ get_ml_prediction ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ (Inference) ***
def get_ml_prediction_inference(df_full):
    report = {"ensemble_score": 0, "ml_score_final": 0, "individual_results": {}, "message": "AI: Ø®Ù†Ø«ÛŒ"}

    if not GLOBAL_MODELS_LOADED:
        report["message"] = "AI: Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù†Ø¯."
        return 0, report

    try:
        # Û±. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ (Ù‡Ù…Ø§Ù†Ù†Ø¯ Ø¨Ø®Ø´ Ø¢Ù…ÙˆØ²Ø´)
        feature_cols = ['RSI_14', 'RSI_6', 'ADX', 'EMA_Diff_Fast', 'EMA_Diff_Slow', 'Returns', 'Volatility', 'Hour', 'DayOfWeek', 'HV_20']
        
        # Ø¢Ø®Ø±ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯
        last_data = df_full.iloc[-1].to_frame().T
        last_data = last_data[['close']].copy() # Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ Key
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        # (Ø¨Ø§ÛŒØ¯ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ ØªÙ…Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ feature_cols Ø¯Ø± df_full ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯)
        
        # Ù…Ù‚ÛŒØ§Ø³â€ŒØ¨Ù†Ø¯ÛŒ
        X_scaled_2d = scaler.transform(last_data[feature_cols])
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø³Ù‡â€ŒØ¨Ø¹Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ LSTM (ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ø´Ù…Ø§ ÛŒÚ© Ù¾Ù†Ø¬Ø±Ù‡ Û±Û° Ú©Ù†Ø¯Ù„ÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒØ¯)
        X_scaled_window = scaler.transform(df_full.iloc[-LSTM_TIME_STEPS:][feature_cols])
        X_scaled_3d = X_scaled_window.reshape(1, LSTM_TIME_STEPS, len(feature_cols))

        ensemble_score_total = 0
        
        # Û². Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ 2D
        for name, model in [('RF', rf_model), ('LR', lr_model), ('XGB', xgb_model)]:
            prob_p = model.predict_proba(X_scaled_2d)[0][1] 
            confidence_score = (prob_p - 0.5) * 100 
            ensemble_score_total += confidence_score
            report["individual_results"][name] = round(confidence_score, 1)
            
        # Û³. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„ 3D (LSTM)
        prob_p_lstm = lstm_model.predict(X_scaled_3d, verbose=0)[0][0]
        confidence_score_lstm = (prob_p_lstm - 0.5) * 100
        ensemble_score_total += confidence_score_lstm
        report["individual_results"]["LSTM"] = round(confidence_score_lstm, 1)

        ml_score = ensemble_score_total / (4 * 40) # 4 Ù…Ø¯Ù„ * 40 (ML_SCORE_NORMALIZER)
        
        report["ensemble_score"] = float(round(ensemble_score_total, 1))
        report["ml_score_final"] = float(round(ml_score, 2))
        report["message"] = f"AI: Score {ml_score:.2f}"
        
        return ml_score, report

    except Exception as e:
        report["message"] = f"AI Inference Error: {str(e)[:100]}..."
        return 0, report


# ---------------------------------------------------------
# Û³. Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Flask (ROUTES)
# ---------------------------------------------------------

@app.route("/", methods=["GET"])
def index():
    """Ù…Ø³ÛŒØ± Ø±ÛŒØ´Ù‡: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯ HTML."""
    return render_template("index.html")

@app.route("/analyze", methods=["GET"])
def analyze():
    try:
        # ... (Ù…Ù†Ø·Ù‚ Ú©Ø§Ù…Ù„ ØªØ§Ø¨Ø¹ analyze Ø§Ø² Ú©Ø¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù‚Ø¨Ù„ÛŒ) ...
        
        # *** ØªØºÛŒÛŒØ± Ø§ØµÙ„ÛŒ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§: ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¬Ø¯ÛŒØ¯ ***
        ml_score, ml_report = get_ml_prediction_inference(df.copy())
        
        # ... (Ø§Ø¯Ø§Ù…Ù‡ Ù…Ù†Ø·Ù‚ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒØŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ùˆ SL/TP) ...
        
        # âš ï¸ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ symbol, interval, size Ùˆ use_htf Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø¯Ø±Ø³Øª Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´ÙˆÙ†Ø¯.
        # ... (Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø¯) ...

    except Exception as e:
        # Ø§Ú¯Ø± Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ§Ø¨Ø¹ analyze Ø±Ø® Ø¯Ù‡Ø¯ØŒ Ø¨Ù‡â€ŒØ¬Ø§ÛŒ Ú©Ø±Ø´ 500ØŒ Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
        return jsonify({"error": f"Internal Error during Analysis: {str(e)}", "status": 500}), 500

# Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ /backtest Ùˆ /optimize Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø­Ø°Ù Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø± Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ØŒ Ø¨Ø§ÛŒØ¯ Ø­Ø°Ù ÛŒØ§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø´ÙˆÙ†Ø¯
# ÛŒØ§ Ø¨Ù‡ Ú¯ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´ÙˆÙ†Ø¯ Ú©Ù‡ Ø¨Ù‡ Ø¬Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ØŒ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ù‚Ø¨Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ù†Ø¯.
# Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø±ØŒ Ø§ÛŒÙ† Ù…Ø³ÛŒØ±Ù‡Ø§ Ø±Ø§ Ø¬Ù‡Øª Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ú©Ø±Ø´ØŒ ØºÛŒØ±ÙØ¹Ø§Ù„ ÛŒØ§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯.

# ---------------------------------------------------------

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port, debug=False)
