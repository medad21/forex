import os
import json
import warnings
import numpy as np
import pandas as pd
import pandas_ta as ta
import requests
import time
import joblib # Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Scikit-learn
import tensorflow as tf # Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ LSTM
from flask import Flask, request, jsonify, render_template

# ---------------------------------------------------------
# Û±. Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒØŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ú©Ù…Ú©ÛŒ (GLOBAL)
# ---------------------------------------------------------

warnings.filterwarnings('ignore')

# Ú©Ù„Ø§Ø³ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ NumPy Ø¨Ù‡ JSON Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer): return int(obj)
        elif isinstance(obj, np.floating): return float(obj)
        elif isinstance(obj, np.ndarray): return obj.tolist()
        return json.JSONEncoder.default(self, obj)

app = Flask(__name__)
app.json_encoder = NumpyEncoder

# ğŸ”‘ API KEYS
API_KEY_TWELVEDATA = os.environ.get("TWELVEDATA_API_KEY") 
API_KEY_ALPHA = os.environ.get("ALPHA_VANTAGE_API_KEY") 

# ğŸ“Š Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
RISK_REWARD_ATR = 1.5           
TARGET_PERIODS = 5              
ML_CONFIDENCE_THRESHOLD = 1.0   
SIGNAL_SCORE_THRESHOLD = 5.0    
LSTM_TIME_STEPS = 10 
TIMEFRAME_MAP = { "15min": "1h", "1h": "4h", "4h": "1day" }
ML_SCORE_NORMALIZER = 40.0 

# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ (Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¢ÙÙ„Ø§ÛŒÙ† Ù¾Ø± Ø´ÙˆÙ†Ø¯)
GLOBAL_RF_IMPORTANCES = {}
GLOBAL_TEST_ACCURACY = "N/A (Offline Training Required)"

# ğŸ§  Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ Scaler ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø± Ø¯Ø± Ø²Ù…Ø§Ù† Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ
try:
    # âš ï¸ Ù…Ø³ÛŒØ±Ù‡Ø§ Ø±Ø§ Ú†Ú© Ú©Ù†ÛŒØ¯: models/lstm_model.h5
    lstm_model = tf.keras.models.load_model('models/lstm_model.h5')
    rf_model = joblib.load('models/rf_model.pkl')
    lr_model = joblib.load('models/lr_model.pkl')
    xgb_model = joblib.load('models/xgb_model.pkl')
    scaler = joblib.load('models/scaler.pkl') 
    GLOBAL_MODELS_LOADED = True
    print("âœ… All ML models and scaler loaded successfully at startup.")
except Exception as e:
    GLOBAL_MODELS_LOADED = False
    print(f"âŒ WARNING: Failed to load models. Running in basic mode. Error: {e}")

# ---------------------------------------------------------
# Û². ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ (Helper Functions)
# ---------------------------------------------------------

# âš ï¸ Ù…Ù‡Ù…: Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ú©Ø¯ Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯ØŒ Ø¨Ø§ÛŒØ¯ ØªÙˆØ§Ø¨Ø¹ Ø²ÛŒØ± Ø±Ø§ Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¬Ø§ÛŒÚ¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯. 
# Ø§ÛŒÙ† ØªÙˆØ§Ø¨Ø¹ Ø´Ø§Ù…Ù„ Ù…Ù†Ø·Ù‚ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø´Ù…Ø§ Ù‡Ø³ØªÙ†Ø¯ Ùˆ Ø¯Ø± Ø§ÛŒÙ† Ø®Ù„Ø§ØµÙ‡ Ø­Ø°Ù Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯:
# - get_candles(symbol, interval, size=2000)
# - check_target(row, df_full, periods, rr_atr)
# - check_divergence(df)
# - get_market_sentiment(symbol)
# - calculate_smart_sl_tp(entry, signal, atr, support, resistance)
# - calculate_indicators_and_targets(df)
# - create_lstm_dataset (Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø³Ù‡â€ŒØ¨Ø¹Ø¯ÛŒ)

# *** ØªØ§Ø¨Ø¹ Ø§Ø³ØªÙ†ØªØ§Ø¬ (Prediction) - Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ ***
def get_ml_prediction_inference(df_full):
    report = {"ensemble_score": 0, "ml_score_final": 0, "individual_results": {}, "message": "AI: Ø®Ù†Ø«ÛŒ"}

    if not GLOBAL_MODELS_LOADED:
        report["message"] = "AI: Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù†Ø¯. (Global Load Failed)"
        return 0, report

    try:
        # Û±. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ (Ø¨Ø§ÛŒØ¯ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù…Ø´Ø§Ø¨Ù‡ Ø²Ù…Ø§Ù† Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø§Ø´Ø¯)
        feature_cols = ['RSI_14', 'RSI_6', 'ADX', 'EMA_Diff_Fast', 'EMA_Diff_Slow', 'Returns', 'Volatility', 'Hour', 'DayOfWeek', 'HV_20']
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø§ÙÛŒ Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        if len(df_full) < LSTM_TIME_STEPS:
            report["message"] = "AI: Ø¯ÛŒØªØ§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ù†Ø¬Ø±Ù‡ LSTM ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."
            return 0, report

        # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ 2D (Ø¨Ø±Ø§ÛŒ RF, XGB, LR)
        last_data_2d = df_full.iloc[-1].to_frame().T[feature_cols]
        X_scaled_2d = scaler.transform(last_data_2d)
        
        # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ 3D (Ø¨Ø±Ø§ÛŒ LSTM)
        X_scaled_window = scaler.transform(df_full.iloc[-LSTM_TIME_STEPS:][feature_cols])
        X_scaled_3d = X_scaled_window.reshape(1, LSTM_TIME_STEPS, len(feature_cols))

        ensemble_score_total = 0
        
        # Û². Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ 2D
        for name, model in [('RF', rf_model), ('LR', lr_model), ('XGB', xgb_model)]:
            prob_p = model.predict_proba(X_scaled_2d)[0][1] 
            confidence_score = (prob_p - 0.5) * 100 
            ensemble_score_total += confidence_score
            report["individual_results"][name] = round(confidence_score, 1)
            
        # Û³. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„ 3D (LSTM)
        prob_p_lstm = lstm_model.predict(X_scaled_3d, verbose=0)[0][0]
        confidence_score_lstm = (prob_p_lstm - 0.5) * 100
        ensemble_score_total += confidence_score_lstm
        report["individual_results"]["LSTM"] = round(confidence_score_lstm, 1)

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ Ensemble
        ml_score = ensemble_score_total / (4 * ML_SCORE_NORMALIZER) 
        
        report["ensemble_score"] = float(round(ensemble_score_total, 1))
        report["ml_score_final"] = float(round(ml_score, 2))
        
        # Ù¾ÛŒØ§Ù… Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø²
        confidence_percent = round(ml_score * 40 * 100 / 400 + 50, 1) # ØªØ¨Ø¯ÛŒÙ„ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø±ØµØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
        if abs(ml_score) < ML_CONFIDENCE_THRESHOLD:
            report["message"] = f"Ensemble: {confidence_percent}% âšª Neutral (Low Confidence)"
        else:
            signal = "Bullish ğŸŸ¢" if ml_score > 0 else "Bearish ğŸ”´"
            report["message"] = f"Ensemble: {confidence_percent}% {signal}"
        
        return ml_score, report

    except Exception as e:
        # Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªÙ†ØªØ§Ø¬ØŒ Ø¨Ù‡ Ø¬Ø§ÛŒ Ú©Ø±Ø´ Ø³Ø±ÙˆØ±ØŒ Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ Ø±Ø§ Ø¯Ø± Ø®Ø±ÙˆØ¬ÛŒ AI Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
        report["message"] = f"AI Inference Error: Check Data/Scaler Compatibility ({str(e)[:50]}...)"
        print(f"FATAL AI INFERENCE ERROR: {e}")
        return 0, report


# ---------------------------------------------------------
# Û³. Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Flask (ROUTES)
# ---------------------------------------------------------

@app.route("/", methods=["GET"])
def index():
    """Ù…Ø³ÛŒØ± Ø±ÛŒØ´Ù‡: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯ HTML."""
    return render_template("index.html")

@app.route("/analyze", methods=["GET"])
def analyze():
    # âš ï¸ ØªÙ…Ø§Ù… Ù…Ù†Ø·Ù‚ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ù‚Ø¨Ù„ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø¬Ø§ÛŒÚ¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯
    try:
        symbol = request.args.get("symbol", "EUR/USD")
        interval = request.args.get("interval", "1h")
        # ... (Ø¨Ù‚ÛŒÙ‡ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ùˆ Ù…Ù†Ø·Ù‚) ...

        df_raw = get_candles(symbol, interval, size=2000)
        if df_raw is None or df_raw.empty: return jsonify({"error": "API Error: Could not fetch market data."}), 500
        
        df = calculate_indicators_and_targets(df_raw.copy()) 
        if df.empty: return jsonify({"error": "Not enough processed data for analysis."}), 500
        
        # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¬Ø¯ÛŒØ¯
        ml_score, ml_report = get_ml_prediction_inference(df.copy())
        
        # ... (Ø§Ø¯Ø§Ù…Ù‡ Ù…Ù†Ø·Ù‚ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¯Ø³ØªÛŒØŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ SL/TP) ...
        # ... (Ø§ÛŒÙ† Ù…Ù†Ø·Ù‚ Ø¨Ø§ÛŒØ¯ Ø§Ø² Ú©Ø¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø´Ù…Ø§ Ú©Ù¾ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯) ...
        
        # Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        return jsonify({
            "symbol": symbol,
            "interval": interval,
            "price": price, # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ price Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª
            "signal": final_signal, # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ final_signal Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª
            "score": round(score, 1), # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ score Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª
            "setup": {"sl": sl, "tp": tp, "rr_ratio": 2.0, "risk_unit_atr": round(atr * 1.5, 5)}, # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ sl, tp, atr Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
            "indicators": {
                "trend": "ØµØ¹ÙˆØ¯ÛŒ â†—" if trend == "uptrend" else "Ù†Ø²ÙˆÙ„ÛŒ â†˜", 
                "rsi": round(rsi, 2), # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ rsi Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª
                "macd": macd_status, # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ macd_status Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª
                "ai_report": {
                    "ensemble_score": ml_report["ensemble_score"],
                    "ml_score_final": ml_report["ml_score_final"],
                    "individual_results": ml_report["individual_results"],
                    "message": ml_report["message"],
                    "accuracy": GLOBAL_TEST_ACCURACY, # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªØºÛŒØ± Ø³Ø±Ø§Ø³Ø±ÛŒ
                    "importances": GLOBAL_RF_IMPORTANCES, # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªØºÛŒØ± Ø³Ø±Ø§Ø³Ø±ÛŒ
                }, 
            }
        })

    except Exception as e:
        return jsonify({"error": f"Internal Error during Analysis: {str(e)}", "status": 500}), 500

# ---------------------------------------------------------
# Û´. ØºÛŒØ±ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø³Ù†Ú¯ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ (Ø­Ù„ Ù…Ø´Ú©Ù„ 500 Ú©Ù†Ø³ÙˆÙ„)
# ---------------------------------------------------------

@app.route("/backtest", methods=["GET"])
def backtest_route():
    """Ù…Ø³ÛŒØ± Ø¨Ú©â€ŒØªØ³Øª: ØºÛŒØ±ÙØ¹Ø§Ù„ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø³Ø±ÙˆØ±."""
    return jsonify({
        "status": "âš ï¸ Error: Backtest is Disabled on Live Server.", 
        "reason": "Training and Backtesting are resource-intensive tasks and must be run offline (locally) to maintain server stability.",
        "solution": "Run your backtesting script locally or upgrade to a high-memory/GPU-enabled server."
    }), 501 # 501: Not Implemented

@app.route("/optimize", methods=["GET"])
def optimize_route():
    """Ù…Ø³ÛŒØ± Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: ØºÛŒØ±ÙØ¹Ø§Ù„ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø³Ø±ÙˆØ±."""
    return jsonify({
        "status": "âš ï¸ Error: Optimization is Disabled on Live Server.",
        "reason": "Optimization requires training and backtesting hundreds of times, which consumes too many resources and will crash the server.",
        "solution": "Run your optimization script locally or upgrade to a high-memory/GPU-enabled server."
    }), 501 # 501: Not Implemented

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port, debug=False)
