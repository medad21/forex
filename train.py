import os
import joblib
import numpy as np
import pandas as pd
import pandas_ta as ta
import yfinance as yf  # Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯ÛŒØªØ§
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
SYMBOL = "EURUSD=X"
PERIOD = "2y"  # Ø¯Ùˆ Ø³Ø§Ù„ Ø¯ÛŒØªØ§
INTERVAL = "1h" # ØªØ§ÛŒÙ… ÙØ±ÛŒÙ… ÛŒÚ© Ø³Ø§Ø¹ØªÙ‡

def calculate_indicators(df):
    # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ (Ù…Ø®ØµÙˆØµ yfinance Ø¬Ø¯ÛŒØ¯)
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.get_level_values(0)
    
    df = df.rename(columns={'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume': 'volume'})
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù…Ø´Ø§Ø¨Ù‡ main.py
    df['Returns'] = df['close'].pct_change()
    df.ta.ema(length=20, append=True)
    df.ta.ema(length=50, append=True)
    df.ta.ema(length=100, append=True)
    df.ta.rsi(length=14, append=True)
    df.ta.rsi(length=6, append=True)
    df.ta.atr(length=14, append=True)
    df.ta.adx(length=14, append=True)
    
    # ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ø´Ø¯Ù‡
    df['Volatility'] = df['high'] - df['low']
    df['Hour'] = df.index.hour
    df['DayOfWeek'] = df.index.dayofweek
    df['HV_20'] = df['Returns'].rolling(window=20).std()
    
    # Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§
    # ØªÙˆØ¬Ù‡: Ù†Ø§Ù…â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø¨Ø§ main.py ÛŒÚ©ÛŒ Ø¨Ø§Ø´Ù†Ø¯
    df['RSI_14'] = df.get(f"RSI_14", df['ta_rsi_14'] if 'ta_rsi_14' in df else 0)
    df['RSI_6'] = df.get(f"RSI_6", df['ta_rsi_6'] if 'ta_rsi_6' in df else 0)
    df['ADX'] = df.get(f"ADX_14", df['ta_adx_14'] if 'ta_adx_14' in df else 0)
    
    # EMA Diffs
    ema20 = df.get(f"EMA_20", df['ta_ema_20'] if 'ta_ema_20' in df else df['close'])
    ema50 = df.get(f"EMA_50", df['ta_ema_50'] if 'ta_ema_50' in df else df['close'])
    ema100 = df.get(f"EMA_100", df['ta_ema_100'] if 'ta_ema_100' in df else df['close'])
    
    df['EMA_Diff_Fast'] = ema20 - ema50
    df['EMA_Diff_Slow'] = ema50 - ema100

    return df.dropna()

def create_target(df):
    # Ù‡Ø¯Ù: Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ø¯Ø± 5 Ú©Ù†Ø¯Ù„ Ø¢ÛŒÙ†Ø¯Ù‡ Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ 1.5 Ø¨Ø±Ø§Ø¨Ø± ATR Ø±Ø´Ø¯ Ú©Ø±Ø¯ = 1 (Ø®Ø±ÛŒØ¯)
    # Ø§Ú¯Ø± Ø§ÙØª Ú©Ø±Ø¯ = 0 (ÙØ±ÙˆØ´/Ø®Ù†Ø«ÛŒ)
    future_period = 5
    atr_multiplier = 1.5
    
    targets = []
    closes = df['close'].values
    highs = df['high'].values
    lows = df['low'].values
    atrs = df['ATRr_14'].values
    
    for i in range(len(closes) - future_period):
        current_close = closes[i]
        atr = atrs[i]
        take_profit = current_close + (atr * atr_multiplier)
        stop_loss = current_close - (atr * atr_multiplier)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡
        future_highs = highs[i+1 : i+future_period+1]
        future_lows = lows[i+1 : i+future_period+1]
        
        if np.max(future_highs) >= take_profit:
            targets.append(1) # Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù…ÙˆÙÙ‚
        else:
            targets.append(0) # Ø¹Ø¯Ù… Ù…ÙˆÙÙ‚ÛŒØª Ø®Ø±ÛŒØ¯ (ÛŒØ§ Ù†Ø²ÙˆÙ„)
            
    # Ù‡Ù…Ú¯Ø§Ù…â€ŒØ³Ø§Ø²ÛŒ Ø·ÙˆÙ„ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¨Ø§ ØªØ§Ø±Ú¯Øªâ€ŒÙ‡Ø§
    df = df.iloc[:len(targets)]
    df['Target'] = targets
    return df

# --- Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ ---
if __name__ == "__main__":
    print(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ {SYMBOL}...")
    df = yf.download(SYMBOL, period=PERIOD, interval=INTERVAL, progress=False)
    
    if df.empty:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯ÛŒØªØ§. ÙˆÛŒâ€ŒÙ¾ÛŒâ€ŒØ§Ù† Ø®ÙˆØ¯ Ø±Ø§ Ú†Ú© Ú©Ù†ÛŒØ¯.")
        exit()
        
    print("âš™ï¸ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§...")
    df = calculate_indicators(df)
    df = create_target(df)
    
    print(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ: {len(df)} Ú©Ù†Ø¯Ù„")

    # ÙÛŒÚ†Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø¯Ù„ Ù…ÛŒâ€ŒØ¨ÛŒÙ†Ø¯ (Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù…Ø«Ù„ main.py)
    feature_cols = ['RSI_14', 'RSI_6', 'ADX', 'EMA_Diff_Fast', 'EMA_Diff_Slow', 'Returns', 'Volatility', 'Hour', 'DayOfWeek', 'HV_20']
    
    X = df[feature_cols].values
    y = df['Target'].values

    # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
    print("âš–ï¸ Ø¢Ù…ÙˆØ²Ø´ Scaler...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    
    # Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡ models
    if not os.path.exists('models'):
        os.makedirs('models')

    # 1. Ø¢Ù…ÙˆØ²Ø´ RF
    print("ğŸŒ² Ø¢Ù…ÙˆØ²Ø´ Random Forest...")
    rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)
    rf.fit(X_train_scaled, y_train)
    joblib.dump(rf, 'models/rf_model.pkl')

    # 2. Ø¢Ù…ÙˆØ²Ø´ LR
    print("ğŸ“ˆ Ø¢Ù…ÙˆØ²Ø´ Logistic Regression...")
    lr = LogisticRegression(C=1.0, random_state=42)
    lr.fit(X_train_scaled, y_train)
    joblib.dump(lr, 'models/lr_model.pkl')

    # 3. Ø¢Ù…ÙˆØ²Ø´ XGB
    print("ğŸš€ Ø¢Ù…ÙˆØ²Ø´ XGBoost...")
    xgb = XGBClassifier(n_estimators=100, learning_rate=0.05, eval_metric='logloss')
    xgb.fit(X_train_scaled, y_train)
    joblib.dump(xgb, 'models/xgb_model.pkl')

    # 4. Ø¢Ù…ÙˆØ²Ø´ LSTM
    print("ğŸ§  Ø¢Ù…ÙˆØ²Ø´ LSTM...")
    time_steps = 10
    def create_lstm_data(data, steps):
        X = []
        for i in range(len(data) - steps):
            X.append(data[i:(i + steps)])
        return np.array(X)

    # Ø¨Ø±Ø§ÛŒ LSTM Ø¨Ø§ÛŒØ¯ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¯ÛŒØªØ§ Ø±Ø§ ÙØ±Ù…Øª Ú©Ù†ÛŒÙ…
    X_lstm = create_lstm_data(scaler.transform(X), time_steps)
    y_lstm = y[time_steps:]
    
    # ØªÙ‚Ø³ÛŒÙ… Ù…Ø¬Ø¯Ø¯ Ù…Ø®ØµÙˆØµ LSTM
    split = int(len(X_lstm) * 0.8)
    X_train_lstm, y_train_lstm = X_lstm[:split], y_lstm[:split]

    lstm = tf.keras.Sequential([
        tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(time_steps, len(feature_cols))),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.LSTM(32),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    lstm.fit(X_train_lstm, y_train_lstm, epochs=5, batch_size=32, verbose=1)
    lstm.save('models/lstm_model.h5')

    # Ø°Ø®ÛŒØ±Ù‡ Scaler
    joblib.dump(scaler, 'models/scaler.pkl')
    
    print("\nâœ… ØªÙ…Ø§Ù…! Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø± Ù¾ÙˆØ´Ù‡ models Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")
    print("Ø­Ø§Ù„Ø§ Ø§ÛŒÙ† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Railway Ø®ÙˆØ¯ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.")
